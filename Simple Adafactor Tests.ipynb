{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f89d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8ce839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adafactor_pytorch import Adafactor\n",
    "from torch.optim import AdamW, Adam\n",
    "from lion_pytorch import Lion\n",
    "import torchvision\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c628314",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),\n",
    "    ]\n",
    ")\n",
    "dataset = load_dataset(\"mnist\")\n",
    "dataset = dataset[\"train\"]\n",
    "def map_label2one_hot(label):\n",
    "    out = np.zeros(10)\n",
    "    out[label] = 1\n",
    "    return out\n",
    "def transform_func(examples):\n",
    "    examples[\"image\"] = [train_transforms(img) for img in examples[\"image\"]]\n",
    "    examples[\"label\"] = [torch.tensor(map_label2one_hot(label)) for label in examples[\"label\"]]\n",
    "    return examples\n",
    "dataset = dataset.with_transform(transform_func)\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"image\"] for example in examples])\n",
    "    pixel_values = pixel_values.to(memory_format=torch.contiguous_format).float()\n",
    "    labels = torch.stack([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "# DataLoaders creation:\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=128,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7656870b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34955c71e554f08a19183d41e727b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/tmppx7ab4f2/main.c:4:10: fatal error: Python.h: No such file or directory\n",
      " #include <Python.h>\n",
      "          ^~~~~~~~~~\n",
      "compilation terminated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 21, in matrix_update_fn_kernel\n",
      "KeyError: ('2-.-0-.-0--d6252949da17ceb5f3a278a70250af13-3b85c7bef5f0a641282f3b73af50f599-3d2aedeb40d6d81c66a42791e268f98b-3498c340fd4b6ee7805fd54b882a04f5-e1f133f98d04093da2078dfc51c36b72-b26258bf01f839199e39d64851821f26-d7c06e3b46e708006c15224aac7a1378-f585402118c8a136948ce0a49cfe122c', (torch.float32, torch.float32, torch.float32, torch.float32, torch.float32, 'fp32', 'fp32', 'fp32', 'fp32', 'fp32', 'fp32', 'i1', 'fp32', 'i32', 'i32', 'i32'), (128,), (True, True, True, True, True, (False,), (False,), (False,), (False,), (False,), (False,), (True, False), (False,), (True, False), (False, False), (True, False)))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_4290/3976814567.py\", line 15, in <module>\n",
      "    optimizer.step()\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/mnt/d/personal_projects/diffusion/adafactor-pytorch/adafactor_pytorch/adafactor_pytorch.py\", line 160, in step\n",
      "    self.update_fn(\n",
      "  File \"/mnt/d/personal_projects/diffusion/adafactor-pytorch/adafactor_pytorch/triton.py\", line 209, in update_fn\n",
      "    matrix_update_fn_kernel[grid](\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 77, in run\n",
      "    timings = {config: self._bench(*args, config=config, **kwargs)\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 77, in <dictcomp>\n",
      "    timings = {config: self._bench(*args, config=config, **kwargs)\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 65, in _bench\n",
      "    return do_bench(kernel_call)\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/triton/testing.py\", line 143, in do_bench\n",
      "    fn()\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/triton/runtime/autotuner.py\", line 63, in kernel_call\n",
      "    self.fn.run(*args, num_warps=config.num_warps, num_stages=config.num_stages, **current)\n",
      "  File \"<string>\", line 41, in matrix_update_fn_kernel\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/triton/compiler.py\", line 1588, in compile\n",
      "    so_path = make_stub(name, signature, constants)\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/triton/compiler.py\", line 1477, in make_stub\n",
      "    so = _build(name, src_path, tmpdir)\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/triton/compiler.py\", line 1392, in _build\n",
      "    ret = subprocess.check_call(cc_cmd)\n",
      "  File \"/usr/lib/python3.10/subprocess.py\", line 369, in check_call\n",
      "    raise CalledProcessError(retcode, cmd)\n",
      "subprocess.CalledProcessError: Command '['/usr/bin/gcc', '/tmp/tmppx7ab4f2/main.c', '-O3', '-I/usr/local/cuda/include', '-I/usr/include/python3.10', '-I/tmp/tmppx7ab4f2', '-shared', '-fPIC', '-lcuda', '-o', '/tmp/tmppx7ab4f2/matrix_update_fn_kernel.cpython-310-x86_64-linux-gnu.so', '-L/usr/lib/wsl/lib']' returned non-zero exit status 1.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1288, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1177, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1049, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 935, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/home/isamu/.local/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1003, in get_records\n",
      "    lines, first = inspect.getsourcelines(etb.tb_frame)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 1121, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"/usr/lib/python3.10/inspect.py\", line 958, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(28*28, 10), torch.nn.Softmax(dim=1)).to(device)\n",
    "optimizer = Adafactor(model.parameters(), betas=(0.9, 0.99), lr=1e-4, use_triton=True)\n",
    "ce_loss = torch.nn.CrossEntropyLoss()\n",
    "losses = []\n",
    "for _ in range(3):\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        pixel_values = batch['pixel_values'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        batch_size = pixel_values.shape[0]\n",
    "        pixel_values = pixel_values.reshape((batch_size, -1))\n",
    "        predicted = model(pixel_values)\n",
    "        loss = ce_loss(predicted, labels)\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(losses[-1])\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(28*28, 10), torch.nn.Softmax(dim=1)).to(device)\n",
    "optimizer = Adafactor(model.parameters(), betas=(0.9, 0.99), lr=1e-4, relative_step=False, scale_parameter=False)\n",
    "ce_loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7065fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for _ in range(3):\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        pixel_values = batch['pixel_values'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        batch_size = pixel_values.shape[0]\n",
    "        pixel_values = pixel_values.reshape((batch_size, -1))\n",
    "        predicted = model(pixel_values)\n",
    "        loss = ce_loss(predicted, labels)\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(losses[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113d5d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7870857",
   "metadata": {},
   "source": [
    "Test AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50175cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(28*28, 10), torch.nn.Softmax(dim=1)).to(device)\n",
    "optimizer = AdamW(model.parameters(), betas=(0.9, 0.99), lr=1e-4)\n",
    "ce_loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414e4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for _ in range(3):\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        pixel_values = batch['pixel_values'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        batch_size = pixel_values.shape[0]\n",
    "        pixel_values = pixel_values.reshape((batch_size, -1))\n",
    "        predicted = model(pixel_values)\n",
    "        loss = ce_loss(predicted, labels)\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(losses[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143372b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56612869",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Linear(28*28, 10), torch.nn.Softmax(dim=1)).to(device)\n",
    "optimizer = Lion(model.parameters(), betas=(0.9, 0.99), lr=1e-5)\n",
    "ce_loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dca192",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for _ in range(3):\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        pixel_values = batch['pixel_values'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        batch_size = pixel_values.shape[0]\n",
    "        pixel_values = pixel_values.reshape((batch_size, -1))\n",
    "        predicted = model(pixel_values)\n",
    "        loss = ce_loss(predicted, labels)\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(losses[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a728f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d09fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
